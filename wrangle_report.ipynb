{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c00ea91",
   "metadata": {},
   "source": [
    "## Reporting: wrangle_report\n",
    "\n",
    "##### A journey through the data wrangling process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173206e7",
   "metadata": {},
   "source": [
    "### Extracting Data\n",
    "\n",
    "I started the process by gathering the data from the 3 different sources using 3 methods.  \n",
    "  - The tweet_archive dataset was downloaded and imported using the pandas read_csv method\n",
    "  - The image prediction data was downloaded using the requests library and the provide url then the data was stored into a file\n",
    "  - The twitter api was used to programmatically download tweet data from twitter and store it in a json file. This took a while as there were a lot of tweet data to receive and the twitter api has to sleep after a while before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b063df",
   "metadata": {},
   "source": [
    "### Assessing Data\n",
    "\n",
    "I assessed the datasets programmatically and visually to check for quality and tidiness issues. The issues I discoverred are below:\n",
    "  - There were missing data in the a lot of the missing columns in both the tweet_archive and tweet_json datasets.\n",
    "  - Some of the columns had incorrect data types and need to be changed.\n",
    "  - The datasets included not only tweets but also retweets. The retweets had to be dropped because we were focusing on just the main tweets\n",
    "  - Some of the dog names were in accurate, etc.\n",
    "For the tidiness, I also found some issues:\n",
    "  - I needed to merge data in some columns of the image prediction and tweet archive data sets to form new columns, dog_breed and dog_stage.\n",
    "  - The tweet_archive and tweet_json datasets had a lot of common column and one had to be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307288a",
   "metadata": {},
   "source": [
    "### Cleaning Data\n",
    "\n",
    "Now, unto the messy part. I proceeded to clean all the issues earlier detected. Here are some of the techniques used in cleaning the data.\n",
    "  - I first made a copy of all three data sets.\n",
    "  - I started with missing values. The expanded_url column of twee_archive dataset coould be gotten by concatenating the tweet_id and url columns which is what I did to fill up the missing values.\n",
    "  - Other columns with missing values more than 50% of the total data available were dropped using the pandas drop method\n",
    "  - I removed the retweet data by matching regex expressions and finding tweets that started with the `RT` marker.\n",
    "  - I then replaced all the irregularities in the name columns with none as extraction from the available data was not feasible.\n",
    "  - I merged the dog stage columns into one by defining a function that checks the four columns and inserts the value that is not none in the dog_stage column, then I applied the function row by row.\n",
    "  - Also defined a function to determine the dog breed by first checking the P_dog columns to make sure that the predictions are actual dog breeds, I then find the max of the p_conf columns to determine the best fit, then return the breed of the dog. This function was also applied row by row using the pandas apply function.\n",
    "  -  After cleaning the individual datasets, I merged them to form one final `tweet_archive_master` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ec2d8f",
   "metadata": {},
   "source": [
    "### Storing Data\n",
    "\n",
    "I proceeded to store the final master dataset into a new csv file before starting my analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
